---
layout: post
title: Spark 集群及高可用集群搭建
description: ""
categories: [Big Data]
keywords: [Linux，大数据,hadoop，spark]

---

## spark 集群搭建

### 安装 jdk 

如果不安装 jdk，就无法使用 jps 命令。

- 解压安装包
- 配置环境变量
- 装载`profile`文件

### 解压spark安装包

```shell
[root@hadoop01 software]# tar -zxvf spark-2.0.2-bin-hadoop2.6.tgz -C /usr/local/apps/
```

### 编辑配置文件

- 进入到 conf 文件夹，修改如下文件名称

```shell
[root@hadoop01 conf]# cp slaves.template slaves
[root@hadoop01 conf]# cp spark-env.sh.template spark-env.sh
```

- 编辑`spark-env.sh`

  ```
  export JAVA_HOME=/usr/local/apps/jdk/
  export SPARK_MASTER_HOST=hadoop01
  export SPARK_MASTER_PORT=7077
  ```

## spark 高可用集群搭建

- 停止 spark 所有服务，修改配置文件 spark-env.sh

```shell
export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=zk1,zk2,zk3 -Dspark.deploy.zookeeper.dir=/spark"
export SPARK_WORKER_CORES=8
export SPARK_WORKER_MEMORY=6g
```

- 配置zookeeper集群

最后启动，在hadoop01节点中 start-all.sh，在hadoop02节点中 start-master.sh ，这样就实现了两个master的高可用，其中一个master为alive，一个为standby。
